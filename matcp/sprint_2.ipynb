{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barplot representing monthly water consumption, as a result of the following specifications given by the user: year, time period (StartMonth,EndMonth) and park identification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this case, the challenge was turning user input into the range of values that we wanted to display. After we gather the input, we can group the data by year and month range in that order, and show the barplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "# Carregar os dados do arquivo CSV\n",
    "dados = pd.read_csv('us09/Datasets_for_US09_US10_and_US11_20240421/water_consumption.csv', delimiter=';')\n",
    "\n",
    "anos_registados = dados[\"Year\"].unique().tolist()\n",
    "ano_selecionado = int(input(\"Insert the year for which you want the data:\"))\n",
    "mes_inicio = int(input(\"Insert the start month for the data:\"))\n",
    "mes_fim = int(input(\"Insert the end month for the data:\"))\n",
    "if ano_selecionado not in anos_registados:\n",
    "  raise ValueError(\"Insert a valid year!\")\n",
    "if mes_inicio < 1 or mes_fim > 12:\n",
    "  raise ValueError(\"Month ranges should be between 1 and 12!\")\n",
    "if mes_inicio > mes_fim:\n",
    "  raise ValueError(\"End month needs to be larger than start month!\")\n",
    "\n",
    "# Converter a coluna 'Consumption' para float\n",
    "dados['Consumption'] = dados['Consumption'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Agrupar os dados por parque e ano e calcular a média de consumo\n",
    "dados_agrupados = dados.query(\"Year == @ano_selecionado and Month >= @mes_inicio and Month <= @mes_fim\").groupby(['Park', 'Month']).agg({'Consumption': 'mean'}).reset_index()\n",
    "\n",
    "# Criar um gráfico de barras para cada parque mostrando a média de consumo de água por mês\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Month', y='Consumption', hue='Park', data=dados_agrupados)\n",
    "\n",
    "# Configurar o título e labels\n",
    "plt.title(f'Monthly water consumption for the year {ano_selecionado} in the months between {calendar.month_abbr[mes_inicio]} and {calendar.month_abbr[mes_fim]}')\n",
    "plt.ylabel('Water consumption (average)')\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that Parque da Cidade shows the highest consumption rates, with the highest consumption values being usually summer months (June to August)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average of monthly costs related to water consumption for each park\n",
    "### As a result of the following specifications given by the user: number of parks to be analyzed, and park identification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the work was done to guarantee that the user inputs valid values; a number of parks larger than 0 and smaller than the number of unique parks in the file, and that the park names exist in the CSV file. After that, we get the entries for those park names, group them by year and month in that order, and calculate the mean of all the \"Consumption\" values so we get an average by each month of each year there are records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('us09/Datasets_for_US09_US10_and_US11_20240421/water_consumption.csv', sep=';', decimal=',')\n",
    "# User input\n",
    "parks = df[\"Park\"].unique().tolist()\n",
    "nParks = int(input(\"How many parks do you want to analyze:\"))\n",
    "if nParks <= 0 or nParks > len(parks):\n",
    "  raise ValueError(f\"The number of parks to analyze needs to be greater than 0 and smaller than {len(parks)}!\")\n",
    "parkNames = []\n",
    "for n in range(0,nParks):\n",
    "  choice = input(f\"Input park name:\\nThe Park name needs to be one of the following:\\n{parks}\\n\")\n",
    "  if choice not in parks:\n",
    "    raise ValueError(\"Park name not in data file!\")\n",
    "  parkNames.append(choice)\n",
    "# Analyzis and display\n",
    "for pn in parkNames:\n",
    "  meanForPark = df.query(\"Park == @pn\").groupby([\"Year\", \"Month\"]).mean(\"Consumption\")[\"Consumption\"]\n",
    "  print(pn)\n",
    "  print(meanForPark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what we tested, the months with the highest consumption values are usually summer months (June to August) which makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The aim is to analyze and compare statistical indicators between the park with the highest and lowest (not null) water consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('us09/Datasets_for_US09_US10_and_US11_20240421/water_consumption.csv', sep=';', decimal=',')\n",
    "parkConsumption_Max = df.groupby('Park')['Consumption'].sum()\n",
    "parkHighestConsumption = parkConsumption_Max.idxmax()\n",
    "parkLowestConsumption = parkConsumption_Max.idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the mean, median, standard deviation, and the coefficient of skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After retrieving the names of the parks with the highest and lowest water consumption, we can apply the next formulas directly using the Pandas library built-in functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('us09/Datasets_for_US09_US10_and_US11_20240421/water_consumption.csv', sep=';', decimal=',')\n",
    "dfForParkHighestConsumption = df.query(\"Park == @parkHighestConsumption\")[\"Consumption\"]\n",
    "print(f\"Mean, median, standard deviation and skewness for park with highest consumption: {parkHighestConsumption}\")\n",
    "print(f\"Mean: {dfForParkHighestConsumption.mean():.2f}\")\n",
    "print(f\"Median: {dfForParkHighestConsumption.median():.2f}\")\n",
    "print(f\"Standard Deviation: {dfForParkHighestConsumption.std():.2f}\")\n",
    "print(f\"Skewness: {dfForParkHighestConsumption.skew():.2f}\")\n",
    "\n",
    "dfForParkLowestConsumption = df.query(\"Park == @parkLowestConsumption\")[\"Consumption\"]\n",
    "print(f\"Mean, median, standard deviation and skewness for park with lowest consumption: {parkLowestConsumption}\")\n",
    "print(f\"Mean: {dfForParkLowestConsumption.mean():.2f}\")\n",
    "print(f\"Median: {dfForParkLowestConsumption.median():.2f}\")\n",
    "print(f\"Standard Deviation: {dfForParkLowestConsumption.std():.2f}\")\n",
    "print(f\"Skewness: {dfForParkLowestConsumption.skew():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The large standard deviation for the park with the highest water consumption indicates that the values are very volatile (we see a large spike during the summer months in one of the previous tasks). Both parks show positive skewness indicating that their highest values are higher than the median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build relative and absolute frequency tables (classified data), considering 5 classes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('us09/Datasets_for_US09_US10_and_US11_20240421/water_consumption.csv', delimiter=';')\n",
    "\n",
    "data['Consumption'] = data['Consumption'].str.replace(',', '.').astype(float)\n",
    "\n",
    "grouped_data = data.groupby(['Park', 'Year', 'Month'])\n",
    "\n",
    "monthly_consumption = grouped_data['Consumption'].sum()\n",
    "\n",
    "# Calculate daily water Consumption\n",
    "def calculate_cost(row):\n",
    "    \n",
    "    park, year, month = row['Park'], row['Year'], row['Month']\n",
    "    consumption = row['Consumption']\n",
    "    \n",
    "    total_monthly_consumption = monthly_consumption[(park, year, month)]\n",
    "\n",
    "    total_monthly_consumption = float(total_monthly_consumption)\n",
    "    \n",
    "    if total_monthly_consumption <= 1000:\n",
    "        cost = consumption * 0.7\n",
    "    else:\n",
    "        cost = consumption * 0.7 * 1.15\n",
    "    \n",
    "    return cost\n",
    "\n",
    "data['Cost'] = data.apply(calculate_cost, axis=1)\n",
    "\n",
    "# Define 5 classes based on the cost column \n",
    "data['Cost_Class'] = pd.cut(data['Cost'], bins=5)\n",
    "\n",
    "# Calculte absolute and relative frequency tables\n",
    "absolut_freq = data['Cost_Class'].value_counts().sort_index()\n",
    "relative_freq = data['Cost_Class'].value_counts(normalize=True).sort_index()\n",
    "\n",
    "print(\"Absolute Frequency Table\")\n",
    "print(absolut_freq)\n",
    "\n",
    "print(\"\\nRelative Frequency Table\")\n",
    "print(relative_freq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each park, check if the data has outliers\n",
    "#### Using the outlier definition as values that deviate from the median by more than 1.5 times the interquartile range;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reusing the variables `parkHighestConsumption` and `parkLowestConsumption`, we had their names to filter through the dataset. After that, it was a matter of calculating the interquartile range with the formula: $$r_q = q_3 − q_1$$ And multiplying by 1.5 to get the upper and lower limits. Then, we just returned the Consumption values that were higher than the upper limit, and lower than the lower limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('us09/Datasets_for_US09_US10_and_US11_20240421/water_consumption.csv', sep=';', decimal=',')\n",
    "dfForParkHighestConsumption = df.query(\"Park == @parkHighestConsumption\")\n",
    "q1Highest = dfForParkHighestConsumption[\"Consumption\"].quantile(0.25)\n",
    "q3Highest = dfForParkHighestConsumption[\"Consumption\"].quantile(0.75)\n",
    "iqrHighest = q3Highest - q1Highest\n",
    "lowerLimitHighest = q1Highest - (1.5 * iqrHighest)\n",
    "upperLimitHighest = q3Highest + (1.5 * iqrHighest)\n",
    "print(dfForParkHighestConsumption[dfForParkHighestConsumption[\"Consumption\"] > upperLimitHighest])\n",
    "\n",
    "dfForParkLowestConsumption = df.query(\"Park == @parkLowestConsumption\")\n",
    "q1Lowest = dfForParkLowestConsumption[\"Consumption\"].quantile(0.25)\n",
    "q3Lowest = dfForParkLowestConsumption[\"Consumption\"].quantile(0.75)\n",
    "iqrLowest = q3Lowest - q1Lowest\n",
    "lowerLimitLowest = q1Lowest - (1.5 * iqrLowest)\n",
    "upperLimitLowest = q3Lowest + (1.5 * iqrLowest)\n",
    "print(dfForParkLowestConsumption[dfForParkLowestConsumption[\"Consumption\"] > upperLimitLowest])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphically represent data through histograms with 10 and 100 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the names of the parks with the highest and lowest water consumption, we can build histograms with the frequency of the consumption values. We displayed them in a 2x2 grid, with the highest consuming park on the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from a CSV file\n",
    "data = pd.read_csv('us09/Datasets_for_US09_US10_and_US11_20240421/water_consumption.csv', delimiter=';')\n",
    "\n",
    "# Convert the 'Consumption' column from string to float\n",
    "data['Consumption'] = data['Consumption'].str.replace(',', '.').astype(float)\n",
    "\n",
    "dfForParkHighestConsumption = data.query(\"Park == @parkHighestConsumption\")\n",
    "dfForParkLowestConsumption = data.query(\"Park == @parkLowestConsumption\")\n",
    "# Create a figure with two subplots (1 row, 2 columns)\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 6))\n",
    "\n",
    "# Highest consumption park - Histogram with 10 bins\n",
    "ax[0][0].hist(dfForParkHighestConsumption['Consumption'], bins=10, edgecolor='black')\n",
    "ax[0][0].set_title(f'{parkHighestConsumption} - Histogram with 10 Classes')\n",
    "ax[0][0].set_xlabel('Value')\n",
    "ax[0][0].set_ylabel('Frequency')\n",
    "\n",
    "# Highest consumption park - Histogram with 100 bins\n",
    "ax[0][1].hist(dfForParkHighestConsumption['Consumption'], bins=100, edgecolor='black')\n",
    "ax[0][1].set_title(f'{parkHighestConsumption} - Histogram with 100 Classes')\n",
    "ax[0][1].set_xlabel('Value')\n",
    "ax[0][1].set_ylabel('Frequency')\n",
    "\n",
    "# Lowest consumption park - Histogram with 10 bins\n",
    "ax[1][0].hist(dfForParkLowestConsumption['Consumption'], bins=10, edgecolor='black')\n",
    "ax[1][0].set_title(f'{parkLowestConsumption} - Histogram with 10 Classes')\n",
    "ax[1][0].set_xlabel('Value')\n",
    "ax[1][0].set_ylabel('Frequency')\n",
    "\n",
    "# Lowest consumption park - Histogram with 100 bins\n",
    "ax[1][1].hist(dfForParkLowestConsumption['Consumption'], bins=100, edgecolor='black')\n",
    "ax[1][1].set_title(f'{parkLowestConsumption} - Histogram with 100 Classes')\n",
    "ax[1][1].set_xlabel('Value')\n",
    "ax[1][1].set_ylabel('Frequency')\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More classes mean that we get more fine-grained data. Each bar represents a smaller range of values so the frequency values are more precise, like with a higher resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a pie chart representing, in percentage, the use of each piece of equipment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get the usage for each equipment from a file that just contains one line per use, we first need to aggregate the equipment names and how many times they appear in the file. After we turn it into a DataFrame, we can create a pie chart from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get equipment names and occurrences\n",
    "df = pd.read_csv(\"us10/EquipmentUsed.csv\")\n",
    "equipmentUseCount = df['Equipment'].value_counts().reset_index()\n",
    "plt.pie(equipmentUseCount['count'], labels=equipmentUseCount['Equipment'], autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that the most used equipments are, in order: walking trails, picnic area, rest benches, and children's playground. We can establish a common patter in the high usage, indicating family activities and leisure rather than exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('us11/Inquiry.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicate the type of each of the three variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Escalao: Qualitative/categorical and ordinal\n",
    "- Y/N: Qualitative/categorical and nominal\n",
    "- Visits: Quantitative/numeric and discrete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicate the proportion of users from each age group who would recommend the park to others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a proportion of users, we need to get the number of users for each category with a recommendation (value \"Y\" for the column \"Y/N\") and divide by the number of users in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"`Y/N` == 'Y'\").groupby('Escalao').size() / df.groupby('Escalao').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that age group 2 (Adult (between 16 and 65 years old)) is more likely to recommend the park to others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a boxplot for each age group, regarding the monthly frequency of use of the park, and draw the main conclusions obtained from this type of graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CSV file is already formatted in a way that we can read directly without additionally treating the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x='Escalao', y='Visits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that age group 3 (Senior (over 65 years old)) visit the park more often on average, and they also have the largest outliers. Which is to say that the people that visited the park the most often during the month, also belonged to the age group 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contributions for each member of the group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1070399: 40%\n",
    "* 1211742: 40%\n",
    "* 1040523: 20%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
